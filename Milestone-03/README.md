# ğŸš€ Milestone 3 â€“ Multi-Agent Orchestration & Memory Management
**LangChain + Gemini + Custom Shared Memory System**

## ğŸ“˜ Overview
**Milestone 3** focuses on building a **Multi-Agent AI System** where two intelligent agents â€” a **Research Agent** and a **Summarizer Agent** â€” collaborate using an orchestrator and shared memory.

This project simulates real-world multi-agent workflows by enabling:
* Independent reasoning by each agent
* Shared knowledge storage
* Autonomous orchestration
* Memory-aware collaboration

---

## ğŸ¯ Key Features

### âœ… Multi-Agent Architecture
* **Research Agent** â†’ Generates detailed information.
* **Summarizer Agent** â†’ Produces concise, structured summaries.

### âœ… Individual Memory
Each agent keeps its own interaction history using simple Python list buffers.

### âœ… Shared Memory
Implemented using **FAISS Vector Store + Fake Embeddings**:
* Stores cross-agent knowledge.
* Enables contextual handoff.
* Prevents information loss.

### âœ… Modular Design
Project structure organized for maintainability:

```text
/agents
    research_agent.py
    summarizer_agent.py
/memory
    sharedmemory.py
orchestrator.py
main.py
```

## ğŸ”„ System Workflow

The following diagram illustrates the data flow between the agents and the shared memory system:

```text
      User Input Topic
             â”‚
             â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Research Agent   â”‚
  â”‚   (LLM + Memory)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    Shared Memory   â”‚
  â”‚  (FAISS + Embeds)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Summarizer Agent  â”‚
  â”‚   (LLM + Memory)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
     Final Output JSON
```

## ğŸ“‚ Project Structure

```text
.
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ research_agent.py
â”‚   â””â”€â”€ summarizer_agent.py
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ sharedmemory.py
â”œâ”€â”€ orchestrator.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸ¤– Agent Details

### ğŸ” Research Agent
* **File:** `agents/research_agent.py`
* **Responsibilities:**
    * Receives the user topic.
    * Checks its own local memory for past context.
    * Generates detailed research output.

In this milestone, it uses a custom `MockLLM` for simulation:

```python
class MockLLM:
    def __call__(self, inputs):
        return {"content": "AI is transforming..."}
```
### âœï¸ Summarizer Agent
* **File:** `agents/summarizer_agent.py`
* **Responsibilities:**
    * Receives research output from the shared memory.
    * Uses local memory to maintain summary consistency across turns.
    * Returns a clean, structured summary string.
 
## ğŸ” Multi-Agent Orchestrator
* **File:** `orchestrator.py`
* **Handles:**
  * Execution order of agents.
  * Memory passing between steps.
  * Coordination between the Research and Summarizer agents.

### Core Process
The orchestrator manages the flow by invoking chains sequentially:

```python
research_result = self.research_chain.invoke({...})
summary = self.summary_chain.invoke({...})
```

## ğŸ“¦ Shared Memory System
* **File:** `memory/sharedmemory.py`

This module implements **FAISS + FakeEmbeddings** to simulate a shared memory vector store between agents.

```python
self.vector_store.add_texts([text])
```
### Why FakeEmbeddings?
* The **Gemini free tier** (and some lightweight models) does not provide direct embedding generation.
* However, **FAISS** (Facebook AI Similarity Search) requires vectors to function.
* Therefore, `FakeEmbeddings` are used to simulate the vectorization process for this milestone.

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Install dependencies
Run the following command to install the required Python packages:

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Configure Environment
Create a `.env` file in the root directory and add your Google Gemini API key:

```env
GOOGLE_API_KEY=your_gemini_api_key
```
### 3ï¸âƒ£ Run the orchestrator
Execute the main script to start the multi-agent system:

```bash
python main.py
```

## ğŸ§ª Example Output

```json
{
  "topic": "Impact of AI on Startup Ecosystem in India",
  "research": "AI is transforming the startup ecosystem...",
  "summary": "Artificial Intelligence accelerates startup growth..."
}
```
## ğŸš€ Future Enhancements
* **Replace MockLLM:** Switch to the real Gemini model for live inference.
* **Add More Agents:** Introduce Analyzer, Validator, and Planner agents.
* **Improve Shared Memory:** Upgrade to real embeddings (instead of FakeEmbeddings).
* **Async Orchestration:** Implement asynchronous processing for better performance.

---

## ğŸ“ Conclusion
This milestone successfully demonstrates:

* [x] **Multi-Agent Collaboration**
* [x] **Custom Orchestration Logic**
* [x] **Shared + Individual Memory**
* [x] **Modular & Scalable Architecture**
